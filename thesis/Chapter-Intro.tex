\chapter{Introduction}
\label{chapter:Introduction}



\section{Deep neural networks for graph structured data}

\subsection{Overview}

In the past decade, deep neural networks have been responsible for several breakthroughs in machine learning ranging from computer vision to natural language processing. [add some citations]. These astounding achievements suggest that deep neural networks have the potential to give rise to many more groundbreaking applications of machine learning. However, a closer look at the breakthroughs cited above reveals that most of these applications focus on one of two kinds of data: images and natural language. An image (in the most general sense) can described as data-points (pixels) on a two-dimensional grid. Natural language on the other hand has a purely one-dimensional structure. In text-form, it can be described as a sequence of words, syllables or characters. In the form of speech, it is a sequence of words or sounds. In either case, the structure of the data is purely sequential meaning that each data point (e.g. a word or a character) is fully described by it's position in the 1D-sequence. (For example think of a word in a novel: it's meaning only depends on the words before and after in the sequence of words - it's position on the page is irrelevant).

Two classes of deep neural architectures were responsible for the breakthroughs: convolutional neural networks (CNNs) for computer vision and recurrent neural networks (RNNs) for natural language. Many improvements have been made to these architectures but the basic architecture remains the same~\footnote{Recently, \textit{Transformer}-architectures have largely replaced RNN-based architectures in natural language processing. Up until this point, advanced RNN-architectures, such as \textit{Long Short Term Memory networks} (LSTMs) have been responsible for the advances in the field.}. For this reason, the basic strategy in applied deep learning is straightforward: Use the latest convolutional architecture that suits the task at hand in computer vision and use the latest RNN-based (e.g. LSTM) or Transformer architecture in natural language processing. However, if the data for the use-case at hand does not fit into either of those two categories, the situation is much more complicated. I other areas, deep neural networks have not outperformed traditional methods by as large a margin and the choice of approach is not as obvious. Examples include for instance documents that comprise both, text and visual elements, such as invoices, legal documents, etc. These documents cannot be fully described as a text-sequence because the position of words, amounts or dates strongly affects their interpretation. However, they also cannot be treated merely as images as the textual information is vital. Thus, the represent textual information on a 2D-grid for which there is no go-to deep learning architecture yet. Another example is 3D data such as point-clouds from 3D-scanners or molecular structures. In theory, CNNs can be extended to three or higher dimensions but in practice this approach is computationally not feasible due to the cubic number of data points in three dimensions.

From these considerations, it becomes clear that is not trivial to extend the success of DNNs from images and language to other kinds of data. Nevertheless, the potential for progress is tremendous and warrants research into neural networks architectures for these kinds of data.

One of the most-versatile data structures is the graph. A graph contains a set of data points called vertices or nodes and a set of edges that define relations between the nodes. A such, as graph is inherently unordered and thus suited for modeling data without predefined order. The only kind of structure that has to be imposed is the definition of the edges.Thus, the only kind of inductive bias of a graph are the relations between nodes. This relational inductive bias is a rather weak bias and allows many kinds of data to be modeled as a graph without imposing some kind of structure onto the data that is not there.

The class of DNNs for graph structured data are called graph convolutional neural networks (GCNNs) or message passing neural networks (MPNNs). The terminology is different between GCNNs and MPNNs but the underlying principles are the same and most neural network architectures for graphs can be described in either framework. While the MPNN terminology is somewhat more intuitive to understand, the GCNN terminology has the advantage of highlighting the parallels to regular CNNs. In this thesis, we will mostly adhere to the MPNN terminology but also borrow terms from GCNNs to highlight the parallels with and differences from regular CNNs. Apologies in advance for the terminology overload - I will try to keep the confusion to a minimum.

Obvious applications of GCNNs are molecular structures (the topic of this thesis), social media networks (or any system where users / people interact with each other) or linked websites. Moreover, many kinds of data that do not have an obvious graph structure at first sight can be modeled as graphs and thus analyzed with GCNNs as well. Examples include 3D point clouds or invoices (with words as nodes and the spacial relationship between words as edges).
[insert figures, some more examples and maybe explanations]
In the remainder of this section we will mostly refer to molecular structures as examples of graph structured data but please keep in mind that the general principles apply to other kinds of graphs as well.

\subsection{Graph convolutional network architecture}

\subsubsection{Challenges of graph structured data for graph convolutional neural networks}
\label{sec:graph-challenges}

There are several challenges of designing neural network architectures for graphs:

\paragraph{No fix-sized dimensionality (globally)}
Each graph can have a different dimensionality in terms of number of nodes and edges. This per se is nothing graph-specific. After all, images also come in different sizes. However, while images can be cropped and scaled to have the same dimension if needed, there is no easy way to do something equivalent with graphs. For instance, in a dataset of 3D molecular structures, the molecules typically have different numbers of atoms (nodes) there is no reasonable way to change this.
\paragraph{No fix-sized dimensionality (locally)}
In a regular graph (without isolated nodes), a node can have 1 to n neighbor-nodes. This has important implications for constructing a graph convolution operation because it requires a function that is invariant to the number of nodes in the neighborhood. 
\paragraph{No inherent order of nodes}
In a graph - at least in undirected graphs - there is no inherent order of the nodes. We can't define a first node, second node, etc. and compare those across graphs (for comparison, note that in images, this is possible, as every image, has an upper left corner, a center, etc.). The same reasoning applies to the neighborhood of any one node: there is no unambiguous way of ordering the neighbor-nodes that allows them to be compared to the neighborhood of another node. Again, this has important implications for graph convolution because it requires a function that is invariant to the order the nodes.

From the last two paragraphs, one can already suspect that graph convolutions require some sort of aggregation function, such as mean, sum or max. These functions work with a variable number of input nodes and invariant to their order (permutation invariant).

Now that we briefly described the properties of the input data, we will examine the possible output formats of a GCNN in the next section. With the input data and the output defined, we will then focus on the transformations that map the input to the output in GCNNs.

\subsubsection{Output format of graph convolutional neural networks}
\label{sec:graph-output}

GCNNs can be used to predict three kinds of target variables:

\paragraph{Graph-properties.}
The target variable is a scalar or a vector per graph. For instance this could be properties of a molecule to be predicted from it's 3D structure. As we will see below, this is the only type of output format where the dimensionality can be constant even though the graphs themselves can vary in dimensionality.
\paragraph{Node-properties.}
The target variable is some property of a single node. Thus, for each node in the graph, a scalar or a vector has to be predicted. In the example of molecular structures, this would be a property of individual atoms.
\paragraph{Edge-properties.}
In this case, the target variable is a scalar or vector-valued edge-property, i.e. a property of the interaction between two nodes. In molecules, an edge-property could for instance be the interaction energy between two atoms.

Note that for the second two types of target variables, the output dimension depends on the dimensionality of the input graph while only the graph-properties as target variable produce output with a constant dimension akin a regular CNN.

\subsubsection{Architecture of graph convolutional neural networks}


The basic building block of a GCNN is graph convolution that maps a node-representation and the nodes neighborhood. We will describe graph convolution using the message passing terminology suggested by Gilmer et. al.~\cite{Gilmer2017}.

The input data can be described as a graph $G$ with	a set of node features where $x_v$ are the features of node $v$ and a (optionally) a set of edge features where $e_{vw}$ describes the edge between node $v$ and node $w$. For simplicity, we will assume undirected graphs where$e_{vw}$ is equal tot $e_{wv}$ which are for modeling structures. However, directed graphs can be described in the same framework if the application requires directed edges. Finally, let $T$ be the number of graph convolutional layers or the number of message passing steps and denote a specific step as $t \in \{1, 2, ..., T\}$. Furthermore, a the node representation at any hidden layer $t$ shall be denoted as $h_v^t$. Note that compared to an image in regular CNNs, the node features $x$ are equivalent to the image while the hidden node representations (also called hidden states) $h$ are equivalent to the feature maps after the first convolutional layer.

During each message passing step, the hidden representation of each node $h_v^t$ is updated to $h_v^{t+1}$ using the following procedure:

\begin{equation}
m_v^{t+1} = \sum_{w \in N(v)} M_t(h_v^t, h_w^t, e_{vw})
\end{equation}

\begin{equation}
h_v^{t+1} = U_t(h_v^t, m_v^{t+1})
\end{equation}

The above two steps are comprised of three functions:

\begin{enumerate}
	\item The message function $M$ which computes the 'message' from node $w$ to node $v$ using the hidden representations of both nodes as well as the features of the connecting edge. Note that a specific architecture may not use all the arguments of the message function in the general framework. For instance, the message function may not use the receiving node hidden states $h_v^t$ (note that it is used in the next step anyway) or the edge features.
	\item An aggregation function that aggregates all the messages from all the neighboring nodes $w \in N(v)$ of node $h$. Any function that is permutation invariant and works for any number of nodes $w$, such as $sum$, $mean$, $min$ or $max$, can be used at this step. However, in practice, the reasonable options are mostly limited to summation and the arithmetic mean.	
	In other papers, aggregation is described as a separate step and the aggregation function denoted with a specific symbol. Here, as well as in Gilmer et al.~\cite{Gilmer2017} we will simply use the summation and note that it could be replaced by the arithmetic mean if appropriate.
	The aggregation is not a function with learned parameters and has to be chosen by the architect of the GCNN. Moreover, it can lead to considerably loss of information. However, this step in inevitable because the neighborhood of a given node can be any number of nodes and they do not have an inherent order as discussed in Section~\ref{sec:graph-challenges}.
	\item The update function $U$ updates the hidden state $h^t$ based on  $m_v^{t+1}$, the aggregated messages from its neighboring nodes.
\end{enumerate}

The details of how these functions are constructed are best explained using a specific example, such as the one explained in Chapter~\ref{chapter:Methods}. For now, it shall suffice to note that both functions $M$ and $U$ could, for instance be a simple MPL (multilayer perceptron) with only one hidden layer. In most architectures the weights of both functions are shared such that $M_t$ and $U_t$ are the same for all $t$. However, this is not a necessity and one could also build a GCNN with different weights for at each graph convolutional layer (= message passing step).

With a block of $T$ message passing steps, one has successfully constructed mapping to create higher-level features akin to the convolutional layers of a regular CNN. Now, we can examine how these higher-level features can be mapped to the desired output. While the message passing part of the GCNN can be the same for each of the three types of output format discussed in Section~\ref{sec:graph-output}, the head of the GCNN needs to be tailored depending on the desired output format.

\begin{enumerate}
	\item \textbf{Graph properties}. To predict graph properties, the higher-level node features computed by the convolutional layers have to be mapped to the target variable using a so-called readout function $R$~\cite{Gilmer2017}. Again, due to the variable number of nodes and the lack of any inherent order, this requires an aggregation function which is permutation invariant and works for different numbers of nodes. Similarly to aggregation during message passing, summation and the arithmetic mean are typically the only viable options. After that, a mapping from the aggregated node hidden states has to be defined - usually a shallow MLP.
	Just as during message passing, the aggregation step in the readout function potentially looses valuable information. However, due to the inherent challenges of graph structured data~\ref{sec:graph-challenges}, it is difficult to find a better solution. As the nodes can be regarded as an unordered set, \textit{Set2Set} [CITATION] and similar methods can be used in the readout function. However, a detailed discussion of these is beyond the scope of this thesis.
	\item \textbf{Node properties}. In this simple case, the readout is much simpler as it requires only a mapping from the final node hidden state $h_T$ to the output variable which can again be achieved with a simple MLP.
	\item \textbf{Edge properties}. To predict edge properties, at readout function needs to take the two connected node's hidden states (and optionally also the edge features) as input and map it to the desired output dimension.~\footnote{Some architectures use edge-updates as described in [ADD SECTION]. In this case, a mapping from the final hidden state to the desired output format can suffice as a readout function - equivalent to how node properties are predicted.}
\end{enumerate}





%{\itshape
%\noindent Explain the reasoning behind graph neural networks:
%
%\begin{itemize}
%	\item no order => permutation invariance required
%	\item no fixed dimension: a node can have 0 to n neighbors => need aggregation function
%\end{itemize}
%
%\noindent Nomenclature:\\
%1) graph conv: complicated but compares well with computer vision\\
%2) message passing: simple, but not analogous to cv
%}


\section{Predicting molecular properties from 3D structure}

\textit{Briefly explain the applications of computational chemistry and computational structural biology} 


\section{Limitations of Graph neural networks for molecular structures}
\label{sec:limitations}

\subsection{Lack of 3D structure representation}

{\itshape
	
sub-subsection: different structural arrangements can lead to same graph => same results

what does not work:\\
* adding coordinates: not invariant to translations and rotations\\
* adding relative positions as edge-features: invariant to translations but not to rotations
=> opposite case to above: now to equivalent structures can be represented with different edge-features

sub-subsection: no down-sampling

this goes hand in hand with: no graph-level or graph-part-level features; only node-features - even when higher level

compare with computer vision

see: results
	}
	
	


