\chapter{Introduction}
\label{chapter:Introduction}



\section{Deep neural networks for graph structured data}

\subsection{Overview}

In the past decade, deep neural networks have been responsible for several breakthroughs in machine learning ranging from computer vision to natural language processing. [add some citations]. These astounding achievements suggest that deep neural networks have the potential to give rise to many more groundbreaking applications of machine learning. However, a closer look at the breakthroughs cited above reveals that most of these applications focus on one of two kinds of data: images and natural language. An image (in the most general sense) can described as data-points (pixels) on a two-dimensional grid. Natural language on the other hand has a purely one-dimensional structure. In text-form, it can be described as a sequence of words, syllables or characters. In the form of speech, it is a sequence of words or sounds. In either case, the structure of the data is purely sequential meaning that each data point (e.g. a word or a character) is fully described by it's position in the 1D-sequence. (For example think of a word in a novel: it's meaning only depends on the words before and after in the sequence of words - it's position on the page is irrelevant).

Two classes of deep neural architectures were responsible for the breakthroughs: convolutional neural networks (CNNs) for computer vision and recurrent neural networks (RNNs) for natural language. Many improvements have been made to these architectures but the basic architecture remains the same~\footnote{Recently, \textit{Transformer}-architectures have largely replaced RNN-based architectures in natural language processing. Up until this point, advanced RNN-architectures, such as \textit{Long Short Term Memory networks} (LSTMs) have been responsible for the advances in the field.}. For this reason, the basic strategy in applied deep learning is straightforward: Use the latest convolutional architecture that suits the task at hand in computer vision and use the latest RNN-based (e.g. LSTM) or Transformer architecture in natural language processing. However, if the data for the use-case at hand does not fit into either of those two categories, the situation is much more complicated. I other areas, deep neural networks have not outperformed traditional methods by as large a margin and the choice of approach is not as obvious. Examples include for instance documents that comprise both, text and visual elements, such as invoices, legal documents, etc. These documents cannot be fully described as a text-sequence because the position of words, amounts or dates strongly affects their interpretation. However, they also cannot be treated merely as images as the textual information is vital. Thus, the represent textual information on a 2D-grid for which there is no go-to deep learning architecture yet. Another example is 3D data such as point-clouds from 3D-scanners or molecular structures. In theory, CNNs can be extended to three or higher dimensions but in practice this approach is computationally not feasible due to the cubic number of data points in three dimensions.

From these considerations, it becomes clear that is not trivial to extend the success of DNNs from images and language to other kinds of data. Nevertheless, the potential for progress is tremendous and warrants research into neural networks architectures for these kinds of data.

One of the most-versatile data structures is the graph. A graph contains a set of data points called vertices or nodes and a set of edges that define relations between the nodes. A such, as graph is inherently unordered and thus suited for modeling data without predefined order. The only kind of structure that has to be imposed is the definition of the edges.Thus, the only kind of inductive bias of a graph are the relations between nodes. This relational inductive bias is a rather weak bias and allows many kinds of data to be modeled as a graph without imposing some kind of structure onto the data that is not there.

The class of DNNs for graph structured data are called graph convolutional neural networks (GCNNs) or message passing neural networks (MPNNs). The terminology is different between GCNNs and MPNNs but the underlying principles are the same and most neural network architectures for graphs can be described in either framework. While the MPNN terminology is somewhat more intuitive to understand, the GCNN terminology has the advantage of highlighting the parallels to regular CNNs. In this thesis, we will mostly adhere to the MPNN terminology but also borrow terms from GCNNs to highlight the parallels with and differences from regular CNNs. Apologies in advance for the terminology overload - I will try to keep the confusion to a minimum.

Obvious applications of GCNNs are molecular structures (the topic of this thesis), social media networks (or any system where users / people interact with each other) or linked websites. Moreover, many kinds of data that do not have an obvious graph structure at first sight can be modeled as graphs and thus analyzed with GCNNs as well. Examples include 3D point clouds or invoices (with words as nodes and the spacial relationship between words as edges).
[insert figures, some more examples and maybe explanations]
In the remainder of this section we will mostly refer to molecular structures as examples of graph structured data but please keep in mind that the general principles apply to other kinds of graphs as well.

\subsection{Graph convolutional network architecture}

\subsubsection{Challenges of graph structured data for graph convolutional neural networks}
\label{sec:graph-challenges}

There are several challenges of designing neural network architectures for graphs:

\paragraph{No fix-sized dimensionality (globally)}
Each graph can have a different dimensionality in terms of number of nodes and edges. This per se is nothing graph-specific. After all, images also come in different sizes. However, while images can be cropped and scaled to have the same dimension if needed, there is no easy way to do something equivalent with graphs. For instance, in a dataset of 3D molecular structures, the molecules typically have different numbers of atoms (nodes) there is no reasonable way to change this.
\paragraph{No fix-sized dimensionality (locally)}
In a regular graph (without isolated nodes), a node can have 1 to n neighbor-nodes. This has important implications for constructing a graph convolution operation because it requires a function that is invariant to the number of nodes in the neighborhood. 
\paragraph{No inherent order of nodes}
In a graph - at least in undirected graphs - there is no inherent order of the nodes. We can't define a first node, second node, etc. and compare those across graphs (for comparison, note that in images, this is possible, as every image, has an upper left corner, a center, etc.). The same reasoning applies to the neighborhood of any one node: there is no unambiguous way of ordering the neighbor-nodes that allows them to be compared to the neighborhood of another node. Again, this has important implications for graph convolution because it requires a function that is invariant to the order the nodes.

From the last two paragraphs, one can already suspect that graph convolutions require some sort of aggregation function, such as mean, sum or max. These functions work with a variable number of input nodes and invariant to their order (permutation invariant).

Now that we briefly described the properties of the input data, we will examine the possible output formats of a GCNN in the next section. With the input data and the output defined, we will then focus on the transformations that map the input to the output in GCNNs.

\subsubsection{Output format of graph convolutional neural networks}
\label{sec:graph-output}

GCNNs can be used to predict three kinds of target variables:

\paragraph{Graph-properties.}
The target variable is a scalar or a vector per graph. For instance this could be properties of a molecule to be predicted from it's 3D structure. As we will see below, this is the only type of output format where the dimensionality can be constant even though the graphs themselves can vary in dimensionality.
\paragraph{Node-properties.}
The target variable is some property of a single node. Thus, for each node in the graph, a scalar or a vector has to be predicted. In the example of molecular structures, this would be a property of individual atoms.
\paragraph{Edge-properties.}
In this case, the target variable is a scalar or vector-valued edge-property, i.e. a property of the interaction between two nodes. In molecules, an edge-property could for instance be the interaction energy between two atoms.

Note that for the second two types of target variables, the output dimension depends on the dimensionality of the input graph while only the graph-properties as target variable produce output with a constant dimension akin a regular CNN.

\subsubsection{Architecture of graph convolutional neural networks}


The basic building block of a GCNN is graph convolution that maps a node-representation and the nodes neighborhood. We will describe graph convolution using the message passing terminology suggested by Gilmer et. al.~\cite{Gilmer2017}.

The input data can be described as a graph $G$ with	a set of node features where $x_v$ are the features of node $v$ and a (optionally) a set of edge features where $e_{vw}$ describes the edge between node $v$ and node $w$. For simplicity, we will assume undirected graphs where$e_{vw}$ is equal tot $e_{wv}$ which are for modeling structures. However, directed graphs can be described in the same framework if the application requires directed edges. Finally, let $T$ be the number of graph convolutional layers or the number of message passing steps and denote a specific step as $t \in \{1, 2, ..., T\}$. Furthermore, a the node representation at any hidden layer $t$ shall be denoted as $h_v^t$. Note that compared to an image in regular CNNs, the node features $x$ are equivalent to the image while the hidden node representations (also called hidden states) $h$ are equivalent to the feature maps after the first convolutional layer.

During each message passing step, the hidden representation of each node $h_v^t$ is updated to $h_v^{t+1}$ using the following procedure:

\begin{equation}
m_v^{t+1} = \sum_{w \in N(v)} M_t(h_v^t, h_w^t, e_{vw})
\end{equation}
\label{eq:message-function}

\begin{equation}
h_v^{t+1} = U_t(h_v^t, m_v^{t+1})
\end{equation}
\label{eq:update-function}

The above two steps are comprised of three functions:

\begin{enumerate}
	\item The message function $M$ which computes the 'message' from node $w$ to node $v$ using the hidden representations of both nodes as well as the features of the connecting edge. Note that a specific architecture may not use all the arguments of the message function in the general framework. For instance, the message function may not use the receiving node hidden states $h_v^t$ (note that it is used in the next step anyway) or the edge features.
	\item An aggregation function that aggregates all the messages from all the neighboring nodes $w \in N(v)$ of node $h$. Any function that is permutation invariant and works for any number of nodes $w$, such as $sum$, $mean$, $min$ or $max$, can be used at this step. However, in practice, the reasonable options are mostly limited to summation and the arithmetic mean.	
	In other papers, aggregation is described as a separate step and the aggregation function denoted with a specific symbol. Here, as well as in Gilmer et al.~\cite{Gilmer2017} we will simply use the summation and note that it could be replaced by the arithmetic mean if appropriate.
	The aggregation is not a function with learned parameters and has to be chosen by the architect of the GCNN. Moreover, it can lead to considerably loss of information. However, this step in inevitable because the neighborhood of a given node can be any number of nodes and they do not have an inherent order as discussed in Section~\ref{sec:graph-challenges}.
	\item The update function $U$ updates the hidden state $h^t$ based on  $m_v^{t+1}$, the aggregated messages from its neighboring nodes.
\end{enumerate}

The details of how these functions are constructed are best explained using a specific example, such as the one explained in Chapter~\ref{chapter:Methods}. For now, it shall suffice to note that both functions $M$ and $U$ could, for instance be a simple MLP (multilayer perceptron) with only one hidden layer. In most architectures the weights of both functions are shared such that $M_t$ and $U_t$ are the same for all $t$. However, this is not a necessity and one could also build a GCNN with different weights for at each graph convolutional layer (= message passing step).

Note in the message passing fist step, only first degree neighbor nodes have an impact on the updated node hidden states. In the second step, second degree neighbors have an indirect impact as they already influenced the hidden state of the first degree neighbors in the previous step. Thus at each step $t$, $h_v^t$ is influence by nodes with a path length of at most $t$ apart from node $v$. Depending on the number of steps $T$, eventually the whole graph might have an indirect influence on the hidden state $h_v^T$. However, the first degree neighbors will always have the most direct influence, followed by the second degree neighbors, etc.

With a block of $T$ message passing steps, one has successfully constructed mapping to create higher-level features akin to the convolutional layers of a regular CNN. Now, we can examine how these higher-level features can be mapped to the desired output. While the message passing part of the GCNN can be the same for each of the three types of output format discussed in Section~\ref{sec:graph-output}, the head of the GCNN needs to be tailored depending on the desired output format.

\begin{enumerate}
	\item \textbf{Graph properties}. To predict graph properties, the higher-level node features computed by the convolutional layers have to be mapped to the target variable using a so-called readout function $R$~\cite{Gilmer2017}. Again, due to the variable number of nodes and the lack of any inherent order, this requires an aggregation function which is permutation invariant and works for different numbers of nodes. Similarly to aggregation during message passing, summation and the arithmetic mean are typically the only viable options. After that, a mapping from the aggregated node hidden states has to be defined - usually a shallow MLP.
	Just as during message passing, the aggregation step in the readout function potentially looses valuable information. However, due to the inherent challenges of graph structured data~\ref{sec:graph-challenges}, it is difficult to find a better solution. As the nodes can be regarded as an unordered set, \textit{Set2Set} [CITATION] and similar methods can be used in the readout function. However, a detailed discussion of these is beyond the scope of this thesis.
	\item \textbf{Node properties}. In this simple case, the readout requires only a mapping from the final node hidden state $h_T$ to the output variable which can again be achieved with a shallow MLP.
	\item \textbf{Edge properties}. To predict edge properties, at readout function needs to take the two connected node's hidden states (and optionally also the edge features) as input and map it to the desired output dimension.~\footnote{Some architectures use edge-updates as described in [ADD SECTION]. In this case, a mapping from the final hidden state to the desired output format can suffice as a readout function - equivalent to how node properties are predicted.}
\end{enumerate}


In summary, a GCNN is composed of two parts: graph convolutional layers and a readout function. The framework introduced here allows to describe highly different architectures using the same terminology. In Chapter~\ref{chapter:Methods}, a the basic architecture of a the GCNN used in this thesis is described in detail. While several different architectures were designed and evaluated in this work [REFERENCE], they are all based on this architecture and thus share key similarities.



\section{Predicting molecular properties from 3D structure with graph convolutional neural networks}

\subsection{Importance of extracting information form 3D molecular structures}

3D structures of small chemical compound as well as large biomolecules are readily available on a large scale [CITATIONS]. However, just knowing the 3D structure of a molecule does not go a long way towards understand it's biological function (in the case of biomolecules) or it's molecular properties and potential applications (in the case of of small organic molecules). For instance, in drug discover, a huge amount of effort goes into laborious and costly experiments on a large scale to find the right small organic molecule for the right therapeutic target. Speeding up and improving this process is highly desirable for obvious reasons.

One way to address this issue is to create purely computational experiments. These experiments are often referred to as in-silico analogous to in-vitro (in a test-tube) in in-vivo (in a living organism). Such in in-silico experiments can be created with molecular structures using molecular dynamics simulations (MDS). In short, MDS creates artificial force-fields to simulate real physical forces to simulated the behavior of molecules under certain conditions. Large biomolecules are usually modeled down to the level of atoms while small molecules are modeled down to the level of subatomic particles (electrons, protons, etc.). While MDS is extremely valuable not only as a proxy for in-vitro experiment but also for understanding the underlying dynamics that produce the experiments outcome. However, it is also extremely challenging mimic realistic experimental conditions, requires an enormous amount of expertise in life science / chemistry and computational skills and extensive experience with MDS itself. Furthermore, MDS is also computationally very expensive and thus cannot be used a cheap proxy for in-vitro experiments at a large scale.

For these reasons, the use of DNNs to predict molecular properties from 3D structures has received increasing attention in recent years. DNNs have the potential to extract valuable information from 3D structures using vast amounts of data with ground-truth without having to explicitly model the underlying physical forces and the interplay of subatomic particles.

\subsection{Modeling molecules as graphs}

When it comes to 3D structures there are really only two basic ways of modeling them from DNNs. The first is to describe them as 3D grids and using 3D convolutional networks simply extending the same architectures used in computer vision by an additional dimension~\cite{Wallach2015}. The problem with this approach is two-fold: First of all, the cubic number of data-points make this method computationally very expensive thus defeating the purpose of finding a less costly alternative for MDS. The second problem is that the information encoded in all these data-points is redundant. In molecular structures, coordinates and types of atoms are fully sufficient to describe the molecule. All other information - such as atomic radius, etc. - are functions of the types of atoms (Hydrogen, Carbon, etc.) or the types of atoms in the neighborhood. Thus when for instance a ten-atom molecule is fully described by ten coordinate vectors and ten (40 numbers), it is excessive an inefficient to model it as a 3D image with tens or hundreds of thousands of pixels. The advantage of the 3D convolutional approach is that 3D structure information is necessarily provided to the model which is a challenge for GCNNs as explained in Section~\ref{sec:limitations}.

The idea of using graphs to model molecules comes quite naturally when looking common representations of molecules such as those shown in figure [REFERENCE: basic molecule graph]. A molecule usually defined as a number of atoms connected by covalent bonds. These kind of bonds involve the sharing of one or more electron-pairs between the bonded atoms and chemically very stable - i.e. it takes takes considerable energy or the involvement of enzymes to break them up. In laymen's terms, covalent bonds can be regarded as 'stable under normal conditions'. In the commonly used molecule graph representation, atoms are shown as letters denoting their type and the covalent bonds are drawn as edges between them as shown in Figure [REFERENCE]. Thus defining a graph where atoms are the nodes and covalent bonds are the edges seems like the most natural way of modeling molecules. However, upon closer examination, the situation is somewhat more complicated.

Atoms interact not only if they are covalently bonded. There is a wide array of non-covalent interactions that have a large influence on molecular properties or function - a simple example being positive and negative (partial) charges. The strength of non-covalent interactions is a function, atom types, distance and the local environment in the 3D structure. Thus, only including covalent bonds leads to considerable loss of information. As an example, consider two atoms can be close in space and interact covalently even though the path length in the covalent graph may be quite large.
With these considerations, another way of representing a molecule as graph would be to simply define an edge between every pair of atoms if the distance is below a certain threshold. Furthermore, the distance could be added as an edge-feature along with a binary feature indicating whether the atoms are covalently bonded or not. This representation has the advantage of considering non-covalent interactions but also introduces many more edges which increases the computational workload. Another way of constructing a graph from a molecular structure is to draw an edge between any given atom and it's k nearest neighbors.

These examples highlight an importance difference between the theory of GCNNs and their application. In the theory, the starting point is graph structured data and all the effort goes into construction the best possible architecture to extraction information from this data. For practical application, the data has to be modeled as graphs in a way that captures the information available in the data in the best possible manner. The choices made in this process may have more influence on the quality of the predictions than the choice of GCNN architecture. After all, if incomplete information is fed into the model, even the best model will yield disappointing results. In the next section, we will examine some challenges that arise modeling molecules as graphs for GCNNs.



\subsection{Limitations of Graph convolutional neural networks for molecular structures}
\label{sec:limitations}

\subsubsection{Lack of 3D structure representation}
\label{sec:lack-of-3d-structure}

In principle, 3D coordinates could simply be added to the node features to obtain a 3D graph. However, this is not meaningful for representing 3D molecular structures. First of all, there is no logical reference point for the origin of the coordinate system. The molecule can be translated arbitrarily along one, two or all three spacial axes without changing anything of relevance. The second problem is, that molecules have no natural orientations i.e. they can be arbitrarily rotated where every rotation is just as valid as any other one (In contrast to everyday objects, such as cupboards or cars, where certain rotations are unlikely to be encountered in everyday life.)

For these reasons, the concrete values of the 3D coordinates which depend on this arbitrary positioning and rotation of the coordinate system do not posses relevant information as such. The translation issue could be addressed by instead using directional vectors from one atom to another as edge-features. These vectors are invariant to the arbitrary translation of the molecule in the coordinate system. However, they depend on the arbitrary rotation of the molecule rendering them also not useful to encode the 3D structure as shown in Section~\ref{sec:direction-vectors}.

In most GCNN architectures, the euclidean distance is provided as an edge feature. This encodes part of the 3D structure in the graph but still looses vital information. It is straightforward to see that for most graphs with distance as edge feature, there are many 3D structures satisfying these constraints. In other words the mapping from 3D structure to graph with distances is unambiguous but the inverse operation is not. It does not take much chemical expertise to conjecture that not providing the full 3D structural information to the model limits it's capability to make accurate predictions. However, there is no easy way to avoid this dilemma and to my knowledge, no satisfying solution has been found so far.

\subsubsection{No down-sampling during feature extraction}

In computer vision with regular CNNs, feature maps are down-sampled to a lower dimension (while expanding the number of channels) every few layers. It makes perfect sense, that higher-level features correspond to larger parts of the original image. Intuitively, one can think a data-point on a feature map close to the end of the convolutional part as containing features that summarize a larger region of the original image. The connection between higher-level features and lower dimension feature maps is so central to regular CNNs that it is hard to imagine it any other way. However, analogous process exists in GCNN.

In GCNN, the higher-level features (i.e. the node hidden states) are always associated to their respective nodes throughout all graph convolutional layers. While each of the node hidden states contains information from the node's environment, there is no representation that summarizes a whole group of nodes. However, after the graph convolutional layers, all the node representations are immediately aggregated to give a graph representation.

In the example of molecules such down-sampled representations could represent groups of atoms instead of just individual atoms. In organic chemistry, there are is a limited number of chemical groups that appear frequently in organic molecules and strongly determine their properties and function called functional groups [CITATION]. Many of those functional groups are composed of only three to four atom and appear very frequently in organic molecules (Carbonyl, Hydroxyl, Amide, Amines, etc.). A model with the ability do down-sample would likely learn representations of these important functional groups. Another benefit of such a mechanism would be to feed angle-information into the model. Note that angles are neither node- nor edge-features. Instead, an angle is a property of a group of three nodes (or you can also see it as a property of a pair of edges). Having a representation for a group of - for example three - nodes would allow to add the angle as a feature thus providing more structural information than only distances.

For these reasons it is my strong believe that future successful GCNN architectures will likely have some sort of down-sampling mechanism that allows learning representations for groups of nodes.


